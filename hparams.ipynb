{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a69ce307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e664ee2",
   "metadata": {},
   "source": [
    "# Copy default hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd263cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--log-wandb'], dest='log_wandb', nargs=0, const=True, default=False, type=None, choices=None, help='log training and validation metrics to wandb', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "\n",
    "# Dataset parameters\n",
    "parser.add_argument('data_dir', metavar='DIR',\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('--dataset', '-d', metavar='NAME', default='',\n",
    "                    help='dataset type (default: ImageFolder/ImageTar if empty)')\n",
    "parser.add_argument('--train-split', metavar='NAME', default='train',\n",
    "                    help='dataset train split (default: train)')\n",
    "parser.add_argument('--val-split', metavar='NAME', default='validation',\n",
    "                    help='dataset validation split (default: validation)')\n",
    "parser.add_argument('--dataset-download', action='store_true', default=False,\n",
    "                    help='Allow download of dataset for torch/ and tfds/ datasets that support it.')\n",
    "parser.add_argument('--class-map', default='', type=str, metavar='FILENAME',\n",
    "                    help='path to class to idx mapping file (default: \"\")')\n",
    "\n",
    "# Model parameters\n",
    "parser.add_argument('--model', default='resnet50', type=str, metavar='MODEL',\n",
    "                    help='Name of model to train (default: \"resnet50\"')\n",
    "parser.add_argument('--pretrained', action='store_true', default=False,\n",
    "                    help='Start with pretrained version of specified network (if avail)')\n",
    "parser.add_argument('--initial-checkpoint', default='', type=str, metavar='PATH',\n",
    "                    help='Initialize model from this checkpoint (default: none)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='Resume full model and optimizer state from checkpoint (default: none)')\n",
    "parser.add_argument('--no-resume-opt', action='store_true', default=False,\n",
    "                    help='prevent resume of optimizer state when resuming model')\n",
    "parser.add_argument('--num-classes', type=int, default=None, metavar='N',\n",
    "                    help='number of label classes (Model default if None)')\n",
    "parser.add_argument('--gp', default=None, type=str, metavar='POOL',\n",
    "                    help='Global pool type, one of (fast, avg, max, avgmax, avgmaxc). Model default if None.')\n",
    "parser.add_argument('--img-size', type=int, default=None, metavar='N',\n",
    "                    help='Image patch size (default: None => model default)')\n",
    "parser.add_argument('--input-size', default=None, nargs=3, type=int,\n",
    "                    metavar='N N N', help='Input all image dimensions (d h w, e.g. --input-size 3 224 224), uses model default if empty')\n",
    "parser.add_argument('--crop-pct', default=None, type=float,\n",
    "                    metavar='N', help='Input image center crop percent (for validation only)')\n",
    "parser.add_argument('--mean', type=float, nargs='+', default=None, metavar='MEAN',\n",
    "                    help='Override mean pixel value of dataset')\n",
    "parser.add_argument('--std', type=float, nargs='+', default=None, metavar='STD',\n",
    "                    help='Override std deviation of of dataset')\n",
    "parser.add_argument('--interpolation', default='', type=str, metavar='NAME',\n",
    "                    help='Image resize interpolation type (overrides model)')\n",
    "parser.add_argument('-b', '--batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for training (default: 128)')\n",
    "parser.add_argument('-vb', '--validation-batch-size', type=int, default=None, metavar='N',\n",
    "                    help='validation batch size override (default: None)')\n",
    "\n",
    "# Optimizer parameters\n",
    "parser.add_argument('--opt', default='sgd', type=str, metavar='OPTIMIZER',\n",
    "                    help='Optimizer (default: \"sgd\"')\n",
    "parser.add_argument('--opt-eps', default=None, type=float, metavar='EPSILON',\n",
    "                    help='Optimizer Epsilon (default: None, use opt default)')\n",
    "parser.add_argument('--opt-betas', default=None, type=float, nargs='+', metavar='BETA',\n",
    "                    help='Optimizer Betas (default: None, use opt default)')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                    help='Optimizer momentum (default: 0.9)')\n",
    "parser.add_argument('--weight-decay', type=float, default=2e-5,\n",
    "                    help='weight decay (default: 2e-5)')\n",
    "parser.add_argument('--clip-grad', type=float, default=None, metavar='NORM',\n",
    "                    help='Clip gradient norm (default: None, no clipping)')\n",
    "parser.add_argument('--clip-mode', type=str, default='norm',\n",
    "                    help='Gradient clipping mode. One of (\"norm\", \"value\", \"agc\")')\n",
    "\n",
    "\n",
    "# Learning rate schedule parameters\n",
    "parser.add_argument('--sched', default='cosine', type=str, metavar='SCHEDULER',\n",
    "                    help='LR scheduler (default: \"step\"')\n",
    "parser.add_argument('--lr', type=float, default=0.05, metavar='LR',\n",
    "                    help='learning rate (default: 0.05)')\n",
    "parser.add_argument('--lr-noise', type=float, nargs='+', default=None, metavar='pct, pct',\n",
    "                    help='learning rate noise on/off epoch percentages')\n",
    "parser.add_argument('--lr-noise-pct', type=float, default=0.67, metavar='PERCENT',\n",
    "                    help='learning rate noise limit percent (default: 0.67)')\n",
    "parser.add_argument('--lr-noise-std', type=float, default=1.0, metavar='STDDEV',\n",
    "                    help='learning rate noise std-dev (default: 1.0)')\n",
    "parser.add_argument('--lr-cycle-mul', type=float, default=1.0, metavar='MULT',\n",
    "                    help='learning rate cycle len multiplier (default: 1.0)')\n",
    "parser.add_argument('--lr-cycle-decay', type=float, default=0.5, metavar='MULT',\n",
    "                    help='amount to decay each learning rate cycle (default: 0.5)')\n",
    "parser.add_argument('--lr-cycle-limit', type=int, default=1, metavar='N',\n",
    "                    help='learning rate cycle limit, cycles enabled if > 1')\n",
    "parser.add_argument('--lr-k-decay', type=float, default=1.0,\n",
    "                    help='learning rate k-decay for cosine/poly (default: 1.0)')\n",
    "parser.add_argument('--warmup-lr', type=float, default=0.0001, metavar='LR',\n",
    "                    help='warmup learning rate (default: 0.0001)')\n",
    "parser.add_argument('--min-lr', type=float, default=1e-6, metavar='LR',\n",
    "                    help='lower lr bound for cyclic schedulers that hit 0 (1e-5)')\n",
    "parser.add_argument('--epochs', type=int, default=300, metavar='N',\n",
    "                    help='number of epochs to train (default: 300)')\n",
    "parser.add_argument('--epoch-repeats', type=float, default=0., metavar='N',\n",
    "                    help='epoch repeat multiplier (number of times to repeat dataset epoch per train epoch).')\n",
    "parser.add_argument('--start-epoch', default=None, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('--decay-epochs', type=float, default=100, metavar='N',\n",
    "                    help='epoch interval to decay LR')\n",
    "parser.add_argument('--warmup-epochs', type=int, default=3, metavar='N',\n",
    "                    help='epochs to warmup LR, if scheduler supports')\n",
    "parser.add_argument('--cooldown-epochs', type=int, default=10, metavar='N',\n",
    "                    help='epochs to cooldown LR at min_lr, after cyclic schedule ends')\n",
    "parser.add_argument('--patience-epochs', type=int, default=10, metavar='N',\n",
    "                    help='patience epochs for Plateau LR scheduler (default: 10')\n",
    "parser.add_argument('--decay-rate', '--dr', type=float, default=0.1, metavar='RATE',\n",
    "                    help='LR decay rate (default: 0.1)')\n",
    "\n",
    "# Augmentation & regularization parameters\n",
    "parser.add_argument('--no-aug', action='store_true', default=False,\n",
    "                    help='Disable all training augmentation, override other train aug args')\n",
    "parser.add_argument('--scale', type=float, nargs='+', default=[0.08, 1.0], metavar='PCT',\n",
    "                    help='Random resize scale (default: 0.08 1.0)')\n",
    "parser.add_argument('--ratio', type=float, nargs='+', default=[3./4., 4./3.], metavar='RATIO',\n",
    "                    help='Random resize aspect ratio (default: 0.75 1.33)')\n",
    "parser.add_argument('--hflip', type=float, default=0.5,\n",
    "                    help='Horizontal flip training aug probability')\n",
    "parser.add_argument('--vflip', type=float, default=0.,\n",
    "                    help='Vertical flip training aug probability')\n",
    "parser.add_argument('--color-jitter', type=float, default=0.4, metavar='PCT',\n",
    "                    help='Color jitter factor (default: 0.4)')\n",
    "parser.add_argument('--aa', type=str, default=None, metavar='NAME',\n",
    "                    help='Use AutoAugment policy. \"v0\" or \"original\". (default: None)'),\n",
    "parser.add_argument('--aug-repeats', type=int, default=0,\n",
    "                    help='Number of augmentation repetitions (distributed training only) (default: 0)')\n",
    "parser.add_argument('--aug-splits', type=int, default=0,\n",
    "                    help='Number of augmentation splits (default: 0, valid: 0 or >=2)')\n",
    "parser.add_argument('--jsd-loss', action='store_true', default=False,\n",
    "                    help='Enable Jensen-Shannon Divergence + CE loss. Use with `--aug-splits`.')\n",
    "parser.add_argument('--bce-loss', action='store_true', default=False,\n",
    "                    help='Enable BCE loss w/ Mixup/CutMix use.')\n",
    "parser.add_argument('--bce-target-thresh', type=float, default=None,\n",
    "                    help='Threshold for binarizing softened BCE targets (default: None, disabled)')\n",
    "parser.add_argument('--reprob', type=float, default=0., metavar='PCT',\n",
    "                    help='Random erase prob (default: 0.)')\n",
    "parser.add_argument('--remode', type=str, default='pixel',\n",
    "                    help='Random erase mode (default: \"pixel\")')\n",
    "parser.add_argument('--recount', type=int, default=1,\n",
    "                    help='Random erase count (default: 1)')\n",
    "parser.add_argument('--resplit', action='store_true', default=False,\n",
    "                    help='Do not random erase first (clean) augmentation split')\n",
    "parser.add_argument('--mixup', type=float, default=0.0,\n",
    "                    help='mixup alpha, mixup enabled if > 0. (default: 0.)')\n",
    "parser.add_argument('--cutmix', type=float, default=0.0,\n",
    "                    help='cutmix alpha, cutmix enabled if > 0. (default: 0.)')\n",
    "parser.add_argument('--cutmix-minmax', type=float, nargs='+', default=None,\n",
    "                    help='cutmix min/max ratio, overrides alpha and enables cutmix if set (default: None)')\n",
    "parser.add_argument('--mixup-prob', type=float, default=1.0,\n",
    "                    help='Probability of performing mixup or cutmix when either/both is enabled')\n",
    "parser.add_argument('--mixup-switch-prob', type=float, default=0.5,\n",
    "                    help='Probability of switching to cutmix when both mixup and cutmix enabled')\n",
    "parser.add_argument('--mixup-mode', type=str, default='batch',\n",
    "                    help='How to apply mixup/cutmix params. Per \"batch\", \"pair\", or \"elem\"')\n",
    "parser.add_argument('--mixup-off-epoch', default=0, type=int, metavar='N',\n",
    "                    help='Turn off mixup after this epoch, disabled if 0 (default: 0)')\n",
    "parser.add_argument('--smoothing', type=float, default=0.1,\n",
    "                    help='Label smoothing (default: 0.1)')\n",
    "parser.add_argument('--train-interpolation', type=str, default='random',\n",
    "                    help='Training interpolation (random, bilinear, bicubic default: \"random\")')\n",
    "parser.add_argument('--drop', type=float, default=0.0, metavar='PCT',\n",
    "                    help='Dropout rate (default: 0.)')\n",
    "parser.add_argument('--drop-connect', type=float, default=None, metavar='PCT',\n",
    "                    help='Drop connect rate, DEPRECATED, use drop-path (default: None)')\n",
    "parser.add_argument('--drop-path', type=float, default=None, metavar='PCT',\n",
    "                    help='Drop path rate (default: None)')\n",
    "parser.add_argument('--drop-block', type=float, default=None, metavar='PCT',\n",
    "                    help='Drop block rate (default: None)')\n",
    "\n",
    "# Batch norm parameters (only works with gen_efficientnet based models currently)\n",
    "parser.add_argument('--bn-tf', action='store_true', default=False,\n",
    "                    help='Use Tensorflow BatchNorm defaults for models that support it (default: False)')\n",
    "parser.add_argument('--bn-momentum', type=float, default=None,\n",
    "                    help='BatchNorm momentum override (if not None)')\n",
    "parser.add_argument('--bn-eps', type=float, default=None,\n",
    "                    help='BatchNorm epsilon override (if not None)')\n",
    "parser.add_argument('--sync-bn', action='store_true',\n",
    "                    help='Enable NVIDIA Apex or Torch synchronized BatchNorm.')\n",
    "parser.add_argument('--dist-bn', type=str, default='reduce',\n",
    "                    help='Distribute BatchNorm stats between nodes after each epoch (\"broadcast\", \"reduce\", or \"\")')\n",
    "parser.add_argument('--split-bn', action='store_true',\n",
    "                    help='Enable separate BN layers per augmentation split.')\n",
    "\n",
    "# Model Exponential Moving Average\n",
    "parser.add_argument('--model-ema', action='store_true', default=False,\n",
    "                    help='Enable tracking moving average of model weights')\n",
    "parser.add_argument('--model-ema-force-cpu', action='store_true', default=False,\n",
    "                    help='Force ema to be tracked on CPU, rank=0 node only. Disables EMA validation.')\n",
    "parser.add_argument('--model-ema-decay', type=float, default=0.9998,\n",
    "                    help='decay factor for model weights moving average (default: 0.9998)')\n",
    "\n",
    "# Misc\n",
    "parser.add_argument('--seed', type=int, default=42, metavar='S',\n",
    "                    help='random seed (default: 42)')\n",
    "parser.add_argument('--worker-seeding', type=str, default='all',\n",
    "                    help='worker seed mode (default: all)')\n",
    "parser.add_argument('--log-interval', type=int, default=50, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--recovery-interval', type=int, default=0, metavar='N',\n",
    "                    help='how many batches to wait before writing recovery checkpoint')\n",
    "parser.add_argument('--checkpoint-hist', type=int, default=10, metavar='N',\n",
    "                    help='number of checkpoints to keep (default: 10)')\n",
    "parser.add_argument('-j', '--workers', type=int, default=4, metavar='N',\n",
    "                    help='how many training processes to use (default: 4)')\n",
    "parser.add_argument('--save-images', action='store_true', default=False,\n",
    "                    help='save images of input bathes every log interval for debugging')\n",
    "parser.add_argument('--amp', action='store_true', default=False,\n",
    "                    help='use NVIDIA Apex AMP or Native AMP for mixed precision training')\n",
    "parser.add_argument('--apex-amp', action='store_true', default=False,\n",
    "                    help='Use NVIDIA Apex AMP mixed precision')\n",
    "parser.add_argument('--native-amp', action='store_true', default=False,\n",
    "                    help='Use Native Torch AMP mixed precision')\n",
    "parser.add_argument('--no-ddp-bb', action='store_true', default=False,\n",
    "                    help='Force broadcast buffers for native DDP to off.')\n",
    "parser.add_argument('--channels-last', action='store_true', default=False,\n",
    "                    help='Use channels_last memory layout')\n",
    "parser.add_argument('--pin-mem', action='store_true', default=False,\n",
    "                    help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')\n",
    "parser.add_argument('--no-prefetcher', action='store_true', default=False,\n",
    "                    help='disable fast prefetcher')\n",
    "parser.add_argument('--output', default='', type=str, metavar='PATH',\n",
    "                    help='path to output folder (default: none, current dir)')\n",
    "parser.add_argument('--experiment', default='', type=str, metavar='NAME',\n",
    "                    help='name of train experiment, name of sub-folder for output')\n",
    "parser.add_argument('--eval-metric', default='top1', type=str, metavar='EVAL_METRIC',\n",
    "                    help='Best metric (default: \"top1\"')\n",
    "parser.add_argument('--tta', type=int, default=0, metavar='N',\n",
    "                    help='Test/inference time augmentation (oversampling) factor. 0=None (default: 0)')\n",
    "parser.add_argument(\"--local_rank\", default=0, type=int)\n",
    "parser.add_argument('--use-multi-epochs-loader', action='store_true', default=False,\n",
    "                    help='use the multi-epochs-loader to save time at the beginning of every epoch')\n",
    "parser.add_argument('--torchscript', dest='torchscript', action='store_true',\n",
    "                    help='convert model torchscript for inference')\n",
    "parser.add_argument('--log-wandb', action='store_true', default=False,\n",
    "                    help='log training and validation metrics to wandb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83feb469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(data_dir='/media/jim/DATA_SSD/imagenet', dataset='', train_split='train', val_split='validation', dataset_download=False, class_map='', model='resnet50', pretrained=False, initial_checkpoint='', resume='', no_resume_opt=False, num_classes=None, gp=None, img_size=None, input_size=None, crop_pct=None, mean=None, std=None, interpolation='', batch_size=128, validation_batch_size=None, opt='sgd', opt_eps=None, opt_betas=None, momentum=0.9, weight_decay=2e-05, clip_grad=None, clip_mode='norm', sched='cosine', lr=0.05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_decay=0.5, lr_cycle_limit=1, lr_k_decay=1.0, warmup_lr=0.0001, min_lr=1e-06, epochs=300, epoch_repeats=0.0, start_epoch=None, decay_epochs=100, warmup_epochs=3, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, no_aug=False, scale=[0.08, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0.5, vflip=0.0, color_jitter=0.4, aa=None, aug_repeats=0, aug_splits=0, jsd_loss=False, bce_loss=False, bce_target_thresh=None, reprob=0.0, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, smoothing=0.1, train_interpolation='random', drop=0.0, drop_connect=None, drop_path=None, drop_block=None, bn_tf=False, bn_momentum=None, bn_eps=None, sync_bn=False, dist_bn='reduce', split_bn=False, model_ema=False, model_ema_force_cpu=False, model_ema_decay=0.9998, seed=42, worker_seeding='all', log_interval=50, recovery_interval=0, checkpoint_hist=10, workers=4, save_images=False, amp=False, apex_amp=False, native_amp=False, no_ddp_bb=False, channels_last=False, pin_mem=False, no_prefetcher=False, output='', experiment='', eval_metric='top1', tta=0, local_rank=0, use_multi_epochs_loader=False, torchscript=False, log_wandb=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parser.parse_args(['/media/jim/DATA_SSD/imagenet'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bacad226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser('DeiT training and evaluation script', add_help=False)\n",
    "    parser.add_argument('--batch-size', default=64, type=int)\n",
    "    parser.add_argument('--epochs', default=300, type=int)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument('--model', default='deit_base_patch16_224', type=str, metavar='MODEL',\n",
    "                        help='Name of model to train')\n",
    "    parser.add_argument('--input-size', default=224, type=int, help='images input size')\n",
    "\n",
    "    parser.add_argument('--drop', type=float, default=0.0, metavar='PCT',\n",
    "                        help='Dropout rate (default: 0.)')\n",
    "    parser.add_argument('--drop-path', type=float, default=0.1, metavar='PCT',\n",
    "                        help='Drop path rate (default: 0.1)')\n",
    "\n",
    "    parser.add_argument('--model-ema', action='store_true')\n",
    "    parser.add_argument('--no-model-ema', action='store_false', dest='model_ema')\n",
    "    parser.set_defaults(model_ema=True)\n",
    "    parser.add_argument('--model-ema-decay', type=float, default=0.99996, help='')\n",
    "    parser.add_argument('--model-ema-force-cpu', action='store_true', default=False, help='')\n",
    "\n",
    "    # Optimizer parameters\n",
    "    parser.add_argument('--opt', default='adamw', type=str, metavar='OPTIMIZER',\n",
    "                        help='Optimizer (default: \"adamw\"')\n",
    "    parser.add_argument('--opt-eps', default=1e-8, type=float, metavar='EPSILON',\n",
    "                        help='Optimizer Epsilon (default: 1e-8)')\n",
    "    parser.add_argument('--opt-betas', default=None, type=float, nargs='+', metavar='BETA',\n",
    "                        help='Optimizer Betas (default: None, use opt default)')\n",
    "    parser.add_argument('--clip-grad', type=float, default=None, metavar='NORM',\n",
    "                        help='Clip gradient norm (default: None, no clipping)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                        help='SGD momentum (default: 0.9)')\n",
    "    parser.add_argument('--weight-decay', type=float, default=0.05,\n",
    "                        help='weight decay (default: 0.05)')\n",
    "    # Learning rate schedule parameters\n",
    "    parser.add_argument('--sched', default='cosine', type=str, metavar='SCHEDULER',\n",
    "                        help='LR scheduler (default: \"cosine\"')\n",
    "    parser.add_argument('--lr', type=float, default=5e-4, metavar='LR',\n",
    "                        help='learning rate (default: 5e-4)')\n",
    "    parser.add_argument('--lr-noise', type=float, nargs='+', default=None, metavar='pct, pct',\n",
    "                        help='learning rate noise on/off epoch percentages')\n",
    "    parser.add_argument('--lr-noise-pct', type=float, default=0.67, metavar='PERCENT',\n",
    "                        help='learning rate noise limit percent (default: 0.67)')\n",
    "    parser.add_argument('--lr-noise-std', type=float, default=1.0, metavar='STDDEV',\n",
    "                        help='learning rate noise std-dev (default: 1.0)')\n",
    "    parser.add_argument('--warmup-lr', type=float, default=1e-6, metavar='LR',\n",
    "                        help='warmup learning rate (default: 1e-6)')\n",
    "    parser.add_argument('--min-lr', type=float, default=1e-5, metavar='LR',\n",
    "                        help='lower lr bound for cyclic schedulers that hit 0 (1e-5)')\n",
    "\n",
    "    parser.add_argument('--decay-epochs', type=float, default=30, metavar='N',\n",
    "                        help='epoch interval to decay LR')\n",
    "    parser.add_argument('--warmup-epochs', type=int, default=5, metavar='N',\n",
    "                        help='epochs to warmup LR, if scheduler supports')\n",
    "    parser.add_argument('--cooldown-epochs', type=int, default=10, metavar='N',\n",
    "                        help='epochs to cooldown LR at min_lr, after cyclic schedule ends')\n",
    "    parser.add_argument('--patience-epochs', type=int, default=10, metavar='N',\n",
    "                        help='patience epochs for Plateau LR scheduler (default: 10')\n",
    "    parser.add_argument('--decay-rate', '--dr', type=float, default=0.1, metavar='RATE',\n",
    "                        help='LR decay rate (default: 0.1)')\n",
    "\n",
    "    # Augmentation parameters\n",
    "    parser.add_argument('--color-jitter', type=float, default=0.4, metavar='PCT',\n",
    "                        help='Color jitter factor (default: 0.4)')\n",
    "    parser.add_argument('--aa', type=str, default='rand-m9-mstd0.5-inc1', metavar='NAME',\n",
    "                        help='Use AutoAugment policy. \"v0\" or \"original\". \" + \\\n",
    "                             \"(default: rand-m9-mstd0.5-inc1)'),\n",
    "    parser.add_argument('--smoothing', type=float, default=0.1, help='Label smoothing (default: 0.1)')\n",
    "    parser.add_argument('--train-interpolation', type=str, default='bicubic',\n",
    "                        help='Training interpolation (random, bilinear, bicubic default: \"bicubic\")')\n",
    "\n",
    "    parser.add_argument('--repeated-aug', action='store_true')\n",
    "    parser.add_argument('--no-repeated-aug', action='store_false', dest='repeated_aug')\n",
    "    parser.set_defaults(repeated_aug=True)\n",
    "\n",
    "    # * Random Erase params\n",
    "    parser.add_argument('--reprob', type=float, default=0.25, metavar='PCT',\n",
    "                        help='Random erase prob (default: 0.25)')\n",
    "    parser.add_argument('--remode', type=str, default='pixel',\n",
    "                        help='Random erase mode (default: \"pixel\")')\n",
    "    parser.add_argument('--recount', type=int, default=1,\n",
    "                        help='Random erase count (default: 1)')\n",
    "    parser.add_argument('--resplit', action='store_true', default=False,\n",
    "                        help='Do not random erase first (clean) augmentation split')\n",
    "\n",
    "    # * Mixup params\n",
    "    parser.add_argument('--mixup', type=float, default=0.8,\n",
    "                        help='mixup alpha, mixup enabled if > 0. (default: 0.8)')\n",
    "    parser.add_argument('--cutmix', type=float, default=1.0,\n",
    "                        help='cutmix alpha, cutmix enabled if > 0. (default: 1.0)')\n",
    "    parser.add_argument('--cutmix-minmax', type=float, nargs='+', default=None,\n",
    "                        help='cutmix min/max ratio, overrides alpha and enables cutmix if set (default: None)')\n",
    "    parser.add_argument('--mixup-prob', type=float, default=1.0,\n",
    "                        help='Probability of performing mixup or cutmix when either/both is enabled')\n",
    "    parser.add_argument('--mixup-switch-prob', type=float, default=0.5,\n",
    "                        help='Probability of switching to cutmix when both mixup and cutmix enabled')\n",
    "    parser.add_argument('--mixup-mode', type=str, default='batch',\n",
    "                        help='How to apply mixup/cutmix params. Per \"batch\", \"pair\", or \"elem\"')\n",
    "\n",
    "    # Distillation parameters\n",
    "    parser.add_argument('--teacher-model', default='regnety_160', type=str, metavar='MODEL',\n",
    "                        help='Name of teacher model to train (default: \"regnety_160\"')\n",
    "    parser.add_argument('--teacher-path', type=str, default='')\n",
    "    parser.add_argument('--distillation-type', default='none', choices=['none', 'soft', 'hard'], type=str, help=\"\")\n",
    "    parser.add_argument('--distillation-alpha', default=0.5, type=float, help=\"\")\n",
    "    parser.add_argument('--distillation-tau', default=1.0, type=float, help=\"\")\n",
    "\n",
    "    # * Finetuning params\n",
    "    parser.add_argument('--finetune', default='', help='finetune from checkpoint')\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument('--data-path', default='/datasets01/imagenet_full_size/061417/', type=str,\n",
    "                        help='dataset path')\n",
    "    parser.add_argument('--data-set', default='IMNET', choices=['CIFAR', 'IMNET', 'INAT', 'INAT19'],\n",
    "                        type=str, help='Image Net dataset path')\n",
    "    parser.add_argument('--inat-category', default='name',\n",
    "                        choices=['kingdom', 'phylum', 'class', 'order', 'supercategory', 'family', 'genus', 'name'],\n",
    "                        type=str, help='semantic granularity')\n",
    "\n",
    "    parser.add_argument('--output_dir', default='',\n",
    "                        help='path where to save, empty for no saving')\n",
    "    parser.add_argument('--device', default='cuda',\n",
    "                        help='device to use for training / testing')\n",
    "    parser.add_argument('--seed', default=0, type=int)\n",
    "    parser.add_argument('--resume', default='', help='resume from checkpoint')\n",
    "    parser.add_argument('--start_epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--eval', action='store_true', help='Perform evaluation only')\n",
    "    parser.add_argument('--dist-eval', action='store_true', default=False, help='Enabling distributed evaluation')\n",
    "    parser.add_argument('--num_workers', default=10, type=int)\n",
    "    parser.add_argument('--pin-mem', action='store_true',\n",
    "                        help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')\n",
    "    parser.add_argument('--no-pin-mem', action='store_false', dest='pin_mem',\n",
    "                        help='')\n",
    "    parser.set_defaults(pin_mem=True)\n",
    "\n",
    "    # distributed training parameters\n",
    "    parser.add_argument('--world_size', default=1, type=int,\n",
    "                        help='number of distributed processes')\n",
    "    parser.add_argument('--dist_url', default='env://', help='url used to set up distributed training')\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "070d7748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=64, epochs=300, model='deit_base_patch16_224', input_size=224, drop=0.0, drop_path=0.1, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', repeated_aug=True, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', teacher_model='regnety_160', teacher_path='', distillation_type='none', distillation_alpha=0.5, distillation_tau=1.0, finetune='', data_path='/datasets01/imagenet_full_size/061417/', data_set='IMNET', inat_category='name', output_dir='', device='cuda', seed=0, resume='', start_epoch=0, eval=False, dist_eval=False, num_workers=10, pin_mem=True, world_size=1, dist_url='env://')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deit_args = get_args_parser().parse_args([])\n",
    "deit_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a392c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model                original: resnet50 deit: deit_base_patch16_224\n",
      "input_size           original: None deit: 224\n",
      "batch_size           original: 128 deit: 64\n",
      "opt                  original: sgd deit: adamw\n",
      "opt_eps              original: None deit: 1e-08\n",
      "weight_decay         original: 2e-05 deit: 0.05\n",
      "lr                   original: 0.05 deit: 0.0005\n",
      "warmup_lr            original: 0.0001 deit: 1e-06\n",
      "min_lr               original: 1e-06 deit: 1e-05\n",
      "start_epoch          original: None deit: 0\n",
      "decay_epochs         original: 100 deit: 30\n",
      "warmup_epochs        original: 3 deit: 5\n",
      "aa                   original: None deit: rand-m9-mstd0.5-inc1\n",
      "reprob               original: 0.0 deit: 0.25\n",
      "mixup                original: 0.0 deit: 0.8\n",
      "cutmix               original: 0.0 deit: 1.0\n",
      "train_interpolation  original: random deit: bicubic\n",
      "drop_path            original: None deit: 0.1\n",
      "model_ema            original: False deit: True\n",
      "model_ema_decay      original: 0.9998 deit: 0.99996\n",
      "seed                 original: 42 deit: 0\n",
      "pin_mem              original: False deit: True\n"
     ]
    }
   ],
   "source": [
    "deit_dict = vars(deit_args)\n",
    "for key, value in vars(args).items():\n",
    "    if key in deit_dict:\n",
    "        if deit_dict[key] != value:\n",
    "            print(f'{key:<20} original: {value} deit: {deit_dict[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85a0a3b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size           original: 128 deit: 64\n",
      "model                original: resnet50 deit: deit_base_patch16_224\n",
      "input_size           original: None deit: 224\n",
      "drop_path            original: None deit: 0.1\n",
      "model_ema            original: False deit: True\n",
      "model_ema_decay      original: 0.9998 deit: 0.99996\n",
      "opt                  original: sgd deit: adamw\n",
      "opt_eps              original: None deit: 1e-08\n",
      "weight_decay         original: 2e-05 deit: 0.05\n",
      "lr                   original: 0.05 deit: 0.0005\n",
      "warmup_lr            original: 0.0001 deit: 1e-06\n",
      "min_lr               original: 1e-06 deit: 1e-05\n",
      "decay_epochs         original: 100 deit: 30\n",
      "warmup_epochs        original: 3 deit: 5\n",
      "aa                   original: None deit: rand-m9-mstd0.5-inc1\n",
      "train_interpolation  original: random deit: bicubic\n",
      "reprob               original: 0.0 deit: 0.25\n",
      "mixup                original: 0.0 deit: 0.8\n",
      "cutmix               original: 0.0 deit: 1.0\n",
      "seed                 original: 42 deit: 0\n",
      "start_epoch          original: None deit: 0\n",
      "pin_mem              original: False deit: True\n"
     ]
    }
   ],
   "source": [
    "arg_dict = vars(args)\n",
    "deit_dict = vars(deit_args)\n",
    "for key, value in deit_dict.items():\n",
    "    if key in arg_dict:\n",
    "        if arg_dict[key] != value:\n",
    "            print(f'{key:<20} original: {arg_dict[key]} deit: {value}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
